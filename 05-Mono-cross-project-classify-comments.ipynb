{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mono cross-project classify comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T07:26:52.500682Z",
     "start_time": "2021-06-29T07:26:52.476683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\user\\\\Research\\\\acora-pure',\n",
       " 'E:\\\\GoogleDrive\\\\acora-data',\n",
       " 'D:\\\\Research\\\\Datasets\\\\BERT')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get paths set either from environment variables or if not set use some default values\n",
    "import os\n",
    "\n",
    "if 'ACORA_HOME_PATH' in os.environ:\n",
    "    acora_home_path = os.environ['ACORA_HOME_PATH']\n",
    "else:\n",
    "    acora_home_path = \"../../acora\"\n",
    "\n",
    "if 'ACORA_DATA_PATH' in os.environ:\n",
    "    data_path = os.environ['ACORA_DATA_PATH']\n",
    "else:\n",
    "    data_path = \"./data\"\n",
    "    \n",
    "if 'BERT_PRETRAIN_MODELS_PATH' in os.environ:\n",
    "    berts_pretrain_path = os.environ['BERT_PRETRAIN_MODELS_PATH']\n",
    "else:\n",
    "    berts_pretrain_path = \"../bert\"\n",
    "\n",
    "acora_home_path, data_path, berts_pretrain_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T07:26:54.526448Z",
     "start_time": "2021-06-29T07:26:54.523448Z"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 102329"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T07:27:04.099825Z",
     "start_time": "2021-06-29T07:26:56.154360Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import matthews_corrcoef as mcc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "\n",
    "import warnings  \n",
    "with warnings.catch_warnings():  \n",
    "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "\n",
    "    import tensorflow as tf\n",
    "\n",
    "    if tf.__version__.startswith(\"1.\"):\n",
    "        os.environ['TF_KERAS'] = '0'\n",
    "        from tensorflow import ConfigProto, Session, set_random_seed\n",
    "        import keras\n",
    "        from keras.backend.tensorflow_backend import set_session\n",
    "        from keras.backend.tensorflow_backend import clear_session\n",
    "        from keras.backend.tensorflow_backend import get_session\n",
    "    else:\n",
    "        os.environ['TF_KERAS'] = '1'\n",
    "        from tensorflow.compat.v1 import ConfigProto, Session, set_random_seed\n",
    "        import tensorflow.compat.v1.keras as keras\n",
    "        tf.get_logger().setLevel('INFO')\n",
    "         \n",
    "    from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "    from keras_bert import Tokenizer, load_trained_model_from_checkpoint\n",
    "    from keras_bert.layers.extract import Extract\n",
    "\n",
    "    from keras_radam import RAdam\n",
    "\n",
    "from acora.vocab import BERTVocab\n",
    "from acora.comments import default_subject_columns, \\\n",
    "    load_comments_files, CommentPurposeTransformer, CommentSubjectTransformer, \\\n",
    "    plot_purpose_confusion_matrix, plot_subjects_confusion_matrix, \\\n",
    "    report_comment_predictions_accuracy, default_purpose_labels, save_comment_predictions_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert_name = 'uncased_L-8_H-512_A-8'\n",
    "bert_name = 'multi_cased_L-12_H-768_A-12'\n",
    "\n",
    "config_path = os.path.join(berts_pretrain_path, bert_name, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(berts_pretrain_path, bert_name, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(berts_pretrain_path, bert_name, 'vocab.txt')\n",
    "with open(config_path, \"r\", encoding='utf', errors='ignore') as json_file:\n",
    "    bert_config = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_use_gpu = False\n",
    "seq_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = [x.name for x in device_lib.list_local_devices() if x.device_type == 'GPU']\n",
    "if not not_use_gpu and len(gpus) == 0:\n",
    "    logger.error(\"You don't have a GPU available on your system, it can affect the performance...\")\n",
    "\n",
    "for gpu_entry in device_lib.list_local_devices():\n",
    "    if hasattr(gpu_entry, 'physical_device_desc'):\n",
    "        print(f\"{gpu_entry.name}: {gpu_entry.physical_device_desc}, {gpu_entry.memory_limit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T07:33:04.471025Z",
     "start_time": "2021-06-29T07:33:04.448031Z"
    }
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "def get_model(seq_len, subject_columns, layer_num, config_path, checkpoint_path, lr=2e-5, \n",
    "              not_use_gpu = not_use_gpu):\n",
    "    \n",
    "    global model\n",
    "\n",
    "    try:\n",
    "        del model \n",
    "    except:\n",
    "        print(\"Unable to delete the model\")\n",
    "    \n",
    "    if tf.__version__.startswith(\"1.\"):\n",
    "        sess = get_session()\n",
    "        clear_session()\n",
    "        sess.close()\n",
    "        gpus = [x.name for x in device_lib.list_local_devices() if x.device_type == 'GPU']\n",
    "        if not not_use_gpu and len(gpus) == 0:\n",
    "            logger.error(\"You don't have a GPU available on your system, it can affect the performance...\")\n",
    "\n",
    "        config = ConfigProto( device_count = {'GPU': 0 if not_use_gpu else len(gpus)})\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "        config.gpu_options.visible_device_list = \"0\"\n",
    "        sess = Session(config=config)\n",
    "        keras.backend.set_session(sess)\n",
    "    else:\n",
    "        sess = tf.compat.v1.keras.backend.get_session()\n",
    "        tf.compat.v1.keras.backend.clear_session()\n",
    "        sess.close()\n",
    "        gpus = [x.name for x in device_lib.list_local_devices() if x.device_type == 'GPU']\n",
    "        if not not_use_gpu and len(gpus) == 0:\n",
    "            logger.error(\"You don't have a GPU available on your system, it can affect the performance...\")\n",
    "\n",
    "        config = ConfigProto( device_count = {'GPU': 0 if not_use_gpu else len(gpus)})\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "        config.gpu_options.visible_device_list = \"0\"\n",
    "        sess = Session(config=config)\n",
    "        tf.compat.v1.keras.backend.set_session(sess)\n",
    "    \n",
    "    \n",
    "    model = load_trained_model_from_checkpoint(\n",
    "        config_path,\n",
    "        checkpoint_path,\n",
    "        training=True,\n",
    "        trainable=True,\n",
    "        seq_len=seq_len\n",
    "    )\n",
    "    \n",
    "    inputs = model.inputs[:2]\n",
    "    #dense = model.get_layer(f'Encoder-{layer_num}-FeedForward-Norm').output\n",
    "    #dense = Extract(index=0, name=\"Extract\")(dense)\n",
    "    dense = model.get_layer('NSP-Dense').output\n",
    "    dense = keras.layers.Dropout(0.1)(dense)\n",
    "\n",
    "\n",
    "    losses = dict()\n",
    "    loss_weights = dict()\n",
    "    outputs = []\n",
    "   \n",
    "    for i, subject_class in enumerate(subject_columns):\n",
    "        outputs.append(keras.layers.Dense(units=1, activation='sigmoid', name=f\"{subject_class}_output\")(dense))\n",
    "        losses[f\"{subject_class}_output\"] = \"binary_crossentropy\"\n",
    "        loss_weights[f\"{subject_class}_output\"] = 1.0\n",
    "\n",
    "    model = keras.models.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        RAdam(learning_rate=lr,beta_1=0.9, beta_2=0.999,warmup_proportion=0.1),\n",
    "        loss=losses, \n",
    "        loss_weights=loss_weights,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T07:27:08.742072Z",
     "start_time": "2021-06-29T07:27:08.543050Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = BERTVocab.load_from_file(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T07:27:08.789069Z",
     "start_time": "2021-06-29T07:27:08.759050Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab.token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T07:27:19.619014Z",
     "start_time": "2021-06-29T07:27:18.423928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data from E:\\GoogleDrive\\acora-data\\wireshark\\wireshark_comments_all.xlsx\n",
      "Loading data from E:\\GoogleDrive\\acora-data\\onap\\onap_comments_all.xlsx\n",
      "Loaded 2,500 rows and 15 cols...\n",
      "Loading data from E:\\GoogleDrive\\acora-data\\mono\\mono-all.xlsx\n",
      "Loaded 172 rows and 15 cols...\n"
     ]
    }
   ],
   "source": [
    "sep = \"$\"\n",
    "\n",
    "line_column = \"line_contents\"\n",
    "message_column = \"message\"\n",
    "purpose_column = \"purpose\"\n",
    "subject_columns = default_subject_columns\n",
    "\n",
    "cols = [line_column, message_column, purpose_column] + subject_columns\n",
    "\n",
    "training_data_paths = [\n",
    "    os.path.join(data_path, \"wireshark\", \"wireshark_comments_all.xlsx\"),\n",
    "    os.path.join(data_path, \"onap\", \"onap_comments_all.xlsx\")\n",
    "]\n",
    "\n",
    "testing_data_paths = [\n",
    "    os.path.join(data_path, \"mono\", \"mono-all.xlsx\"),\n",
    "]\n",
    "reviews_train_df = load_comments_files(training_data_paths, cols, sep)\n",
    "reviews_test_df = load_comments_files(testing_data_paths, cols, sep)\n",
    "\n",
    "duplicates = pd.concat(g for _, g in reviews_train_df.groupby(message_column) if len(g) > 1)\n",
    "unique = pd.concat(g for _, g in reviews_train_df.groupby(message_column) if len(g) == 1)\n",
    "reviews_train_df = pd.concat([duplicates, unique])\n",
    "\n",
    "duplicates = pd.concat(g for _, g in reviews_test_df.groupby(message_column) if len(g) > 1)\n",
    "unique = pd.concat(g for _, g in reviews_test_df.groupby(message_column) if len(g) == 1)\n",
    "reviews_test_df = pd.concat([duplicates, unique])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T07:28:06.331458Z",
     "start_time": "2021-06-29T07:28:06.315459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2500, 15), (172, 15))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train_df.shape,  reviews_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T07:29:21.541513Z",
     "start_time": "2021-06-29T07:29:20.792031Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_train_messages = [tokenizer.encode(str(text), max_len=seq_len)[0] for text in reviews_train_df[message_column].tolist()] \n",
    "x_train = [np.array(tokenized_train_messages), np.zeros_like(tokenized_train_messages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T07:29:57.672875Z",
     "start_time": "2021-06-29T07:29:57.629433Z"
    }
   },
   "outputs": [],
   "source": [
    "subject_transformer_train = CommentSubjectTransformer(reviews_train_df, subject_columns)\n",
    "y_train_subject = subject_transformer_train.encode_one_hot_all_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:36:57.474460Z",
     "start_time": "2021-06-29T08:36:57.400446Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_test_messages = [tokenizer.encode(str(text), max_len=seq_len)[0] for text in reviews_test_df[message_column].tolist()] \n",
    "x_test = [np.array(tokenized_test_messages), np.zeros_like(tokenized_test_messages)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T07:30:57.830691Z",
     "start_time": "2021-06-29T07:30:57.810693Z"
    }
   },
   "outputs": [],
   "source": [
    "subject_transformer_test = CommentSubjectTransformer(reviews_test_df, subject_columns)\n",
    "y_test_subject = subject_transformer_test.encode_one_hot_all_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T07:34:15.067991Z",
     "start_time": "2021-06-29T07:34:15.055990Z"
    }
   },
   "outputs": [],
   "source": [
    "y_all_train = dict()\n",
    "for i, subject_class in enumerate(subject_columns):\n",
    "    y_all_train[f\"{subject_class}_output\"] = subject_transformer_train.encode_binary_single_subject(subject_class).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T07:34:40.336813Z",
     "start_time": "2021-06-29T07:34:40.327817Z"
    }
   },
   "outputs": [],
   "source": [
    "y_all_test = dict()\n",
    "for i, subject_class in enumerate(subject_columns):\n",
    "    y_all_test[f\"{subject_class}_output\"] = subject_transformer_test.encode_binary_single_subject(subject_class).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T07:35:15.826276Z",
     "start_time": "2021-06-29T07:35:15.793276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated subject weights: {'code_design': array([0.53011026, 8.8028169 ]), 'code_style': array([0.54324207, 6.28140704]), 'code_naming': array([ 0.51845707, 14.04494382]), 'code_logic': array([0.76593137, 1.44009217]), 'code_io': array([ 0.51208521, 21.18644068]), 'code_data': array([1.52625153, 0.743605  ]), 'code_doc': array([ 0.52631579, 10.        ]), 'code_api': array([0.56028687, 4.64684015]), 'compatibility': array([ 0.51610239, 16.02564103]), 'rule_def': array([ 0.51588939, 16.23376623]), 'config_commit_patch_review': array([ 0.52039967, 12.75510204]), 'config_building_installing': array([ 0.52345059, 11.16071429])}\n"
     ]
    }
   ],
   "source": [
    "subject_class_weights_train = subject_transformer_train.class_weights()\n",
    "print(f\"Calculated subject weights: {subject_class_weights_train}\")\n",
    "\n",
    "class_weights_all_train = dict()\n",
    "for i, subject_class in enumerate(subject_columns):\n",
    "    class_weights_all_train[f\"{subject_class}_output\"] = subject_class_weights_train[subject_class]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:04:12.590004Z",
     "start_time": "2021-06-29T07:37:31.377180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x000001CD8308BDA0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x000001CD8308BDA0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x000001CDBA51AA20>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x000001CDBA51AA20>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001CDBA53DFD0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x000001CDBA53DFD0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x000001CDBA5540B8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x000001CDBA5540B8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x000001CDBA5E0E48>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x000001CDBA5E0E48>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x000001CDBA5D8F28>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x000001CDBA5D8F28>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method EmbeddingSimilarity.call of <keras_bert.layers.embedding.EmbeddingSimilarity object at 0x000001D071F2BC50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method EmbeddingSimilarity.call of <keras_bert.layers.embedding.EmbeddingSimilarity object at 0x000001D071F2BC50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Masked.call of <keras_bert.layers.masked.Masked object at 0x000001D071F41EB8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Masked.call of <keras_bert.layers.masked.Masked object at 0x000001D071F41EB8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Extract.call of <keras_bert.layers.extract.Extract object at 0x000001D071F48B38>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Extract.call of <keras_bert.layers.extract.Extract object at 0x000001D071F48B38>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001D071F8DC80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001D071F8DC80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "105/105 [==============================] - 104s 991ms/step - loss: 5.1688 - code_design_output_loss: 0.4354 - code_style_output_loss: 0.4803 - code_naming_output_loss: 0.2675 - code_logic_output_loss: 0.6442 - code_io_output_loss: 0.3639 - code_data_output_loss: 0.6792 - code_doc_output_loss: 0.3206 - code_api_output_loss: 0.4318 - compatibility_output_loss: 0.3669 - rule_def_output_loss: 0.3663 - config_commit_patch_review_output_loss: 0.4030 - config_building_installing_output_loss: 0.4097 - code_design_output_accuracy: 0.8096 - code_style_output_accuracy: 0.7500 - code_naming_output_accuracy: 0.9640 - code_logic_output_accuracy: 0.6176 - code_io_output_accuracy: 0.8976 - code_data_output_accuracy: 0.5464 - code_doc_output_accuracy: 0.9484 - code_api_output_accuracy: 0.8824 - compatibility_output_accuracy: 0.8312 - rule_def_output_accuracy: 0.9084 - config_commit_patch_review_output_accuracy: 0.8124 - config_building_installing_output_accuracy: 0.7820\n",
      "Epoch 2/15\n",
      "105/105 [==============================] - 102s 974ms/step - loss: 2.9806 - code_design_output_loss: 0.2240 - code_style_output_loss: 0.2816 - code_naming_output_loss: 0.1529 - code_logic_output_loss: 0.5384 - code_io_output_loss: 0.1245 - code_data_output_loss: 0.5178 - code_doc_output_loss: 0.2033 - code_api_output_loss: 0.3067 - compatibility_output_loss: 0.1416 - rule_def_output_loss: 0.1495 - config_commit_patch_review_output_loss: 0.1671 - config_building_installing_output_loss: 0.1731 - code_design_output_accuracy: 0.9432 - code_style_output_accuracy: 0.9204 - code_naming_output_accuracy: 0.9644 - code_logic_output_accuracy: 0.6936 - code_io_output_accuracy: 0.9764 - code_data_output_accuracy: 0.7400 - code_doc_output_accuracy: 0.9500 - code_api_output_accuracy: 0.8936 - compatibility_output_accuracy: 0.9688 - rule_def_output_accuracy: 0.9692 - config_commit_patch_review_output_accuracy: 0.9608 - config_building_installing_output_accuracy: 0.9548\n",
      "Epoch 3/15\n",
      "105/105 [==============================] - 101s 964ms/step - loss: 2.6052 - code_design_output_loss: 0.2144 - code_style_output_loss: 0.2455 - code_naming_output_loss: 0.1368 - code_logic_output_loss: 0.4483 - code_io_output_loss: 0.1131 - code_data_output_loss: 0.4233 - code_doc_output_loss: 0.1941 - code_api_output_loss: 0.2593 - compatibility_output_loss: 0.1286 - rule_def_output_loss: 0.1400 - config_commit_patch_review_output_loss: 0.1545 - config_building_installing_output_loss: 0.1475 - code_design_output_accuracy: 0.9432 - code_style_output_accuracy: 0.9220 - code_naming_output_accuracy: 0.9644 - code_logic_output_accuracy: 0.7744 - code_io_output_accuracy: 0.9764 - code_data_output_accuracy: 0.8076 - code_doc_output_accuracy: 0.9500 - code_api_output_accuracy: 0.8992 - compatibility_output_accuracy: 0.9688 - rule_def_output_accuracy: 0.9692 - config_commit_patch_review_output_accuracy: 0.9608 - config_building_installing_output_accuracy: 0.9556\n",
      "Epoch 4/15\n",
      "105/105 [==============================] - 101s 963ms/step - loss: 2.2310 - code_design_output_loss: 0.2038 - code_style_output_loss: 0.1672 - code_naming_output_loss: 0.1108 - code_logic_output_loss: 0.3831 - code_io_output_loss: 0.1091 - code_data_output_loss: 0.3529 - code_doc_output_loss: 0.1833 - code_api_output_loss: 0.2197 - compatibility_output_loss: 0.1142 - rule_def_output_loss: 0.1266 - config_commit_patch_review_output_loss: 0.1339 - config_building_installing_output_loss: 0.1264 - code_design_output_accuracy: 0.9432 - code_style_output_accuracy: 0.9476 - code_naming_output_accuracy: 0.9652 - code_logic_output_accuracy: 0.8216 - code_io_output_accuracy: 0.9764 - code_data_output_accuracy: 0.8456 - code_doc_output_accuracy: 0.9500 - code_api_output_accuracy: 0.9140 - compatibility_output_accuracy: 0.9688 - rule_def_output_accuracy: 0.9692 - config_commit_patch_review_output_accuracy: 0.9604 - config_building_installing_output_accuracy: 0.9576\n",
      "Epoch 5/15\n",
      "105/105 [==============================] - 101s 962ms/step - loss: 1.8787 - code_design_output_loss: 0.1888 - code_style_output_loss: 0.1154 - code_naming_output_loss: 0.0920 - code_logic_output_loss: 0.3167 - code_io_output_loss: 0.1044 - code_data_output_loss: 0.2773 - code_doc_output_loss: 0.1629 - code_api_output_loss: 0.1773 - compatibility_output_loss: 0.1057 - rule_def_output_loss: 0.1102 - config_commit_patch_review_output_loss: 0.1147 - config_building_installing_output_loss: 0.1132 - code_design_output_accuracy: 0.9436 - code_style_output_accuracy: 0.9680 - code_naming_output_accuracy: 0.9696 - code_logic_output_accuracy: 0.8564 - code_io_output_accuracy: 0.9764 - code_data_output_accuracy: 0.8932 - code_doc_output_accuracy: 0.9500 - code_api_output_accuracy: 0.9356 - compatibility_output_accuracy: 0.9692 - rule_def_output_accuracy: 0.9692 - config_commit_patch_review_output_accuracy: 0.9616 - config_building_installing_output_accuracy: 0.9600\n",
      "Epoch 6/15\n",
      "105/105 [==============================] - 101s 963ms/step - loss: 1.5891 - code_design_output_loss: 0.1701 - code_style_output_loss: 0.0844 - code_naming_output_loss: 0.0736 - code_logic_output_loss: 0.2619 - code_io_output_loss: 0.0996 - code_data_output_loss: 0.2291 - code_doc_output_loss: 0.1414 - code_api_output_loss: 0.1431 - compatibility_output_loss: 0.0954 - rule_def_output_loss: 0.0983 - config_commit_patch_review_output_loss: 0.0897 - config_building_installing_output_loss: 0.1025 - code_design_output_accuracy: 0.9452 - code_style_output_accuracy: 0.9752 - code_naming_output_accuracy: 0.9788 - code_logic_output_accuracy: 0.8900 - code_io_output_accuracy: 0.9764 - code_data_output_accuracy: 0.9144 - code_doc_output_accuracy: 0.9556 - code_api_output_accuracy: 0.9508 - compatibility_output_accuracy: 0.9704 - rule_def_output_accuracy: 0.9688 - config_commit_patch_review_output_accuracy: 0.9684 - config_building_installing_output_accuracy: 0.9600\n",
      "Epoch 7/15\n",
      "105/105 [==============================] - 101s 964ms/step - loss: 1.2876 - code_design_output_loss: 0.1494 - code_style_output_loss: 0.0581 - code_naming_output_loss: 0.0557 - code_logic_output_loss: 0.1964 - code_io_output_loss: 0.0933 - code_data_output_loss: 0.1601 - code_doc_output_loss: 0.1204 - code_api_output_loss: 0.1137 - compatibility_output_loss: 0.0869 - rule_def_output_loss: 0.0911 - config_commit_patch_review_output_loss: 0.0784 - config_building_installing_output_loss: 0.0839 - code_design_output_accuracy: 0.9512 - code_style_output_accuracy: 0.9852 - code_naming_output_accuracy: 0.9836 - code_logic_output_accuracy: 0.9268 - code_io_output_accuracy: 0.9764 - code_data_output_accuracy: 0.9424 - code_doc_output_accuracy: 0.9636 - code_api_output_accuracy: 0.9656 - compatibility_output_accuracy: 0.9708 - rule_def_output_accuracy: 0.9700 - config_commit_patch_review_output_accuracy: 0.9748 - config_building_installing_output_accuracy: 0.9688\n",
      "Epoch 8/15\n",
      "105/105 [==============================] - 101s 964ms/step - loss: 1.0624 - code_design_output_loss: 0.1287 - code_style_output_loss: 0.0505 - code_naming_output_loss: 0.0418 - code_logic_output_loss: 0.1549 - code_io_output_loss: 0.0875 - code_data_output_loss: 0.1216 - code_doc_output_loss: 0.0990 - code_api_output_loss: 0.1038 - compatibility_output_loss: 0.0729 - rule_def_output_loss: 0.0767 - config_commit_patch_review_output_loss: 0.0601 - config_building_installing_output_loss: 0.0648 - code_design_output_accuracy: 0.9576 - code_style_output_accuracy: 0.9868 - code_naming_output_accuracy: 0.9916 - code_logic_output_accuracy: 0.9484 - code_io_output_accuracy: 0.9764 - code_data_output_accuracy: 0.9600 - code_doc_output_accuracy: 0.9700 - code_api_output_accuracy: 0.9660 - compatibility_output_accuracy: 0.9756 - rule_def_output_accuracy: 0.9760 - config_commit_patch_review_output_accuracy: 0.9832 - config_building_installing_output_accuracy: 0.9764\n",
      "Epoch 9/15\n",
      "105/105 [==============================] - 101s 966ms/step - loss: 0.8693 - code_design_output_loss: 0.1059 - code_style_output_loss: 0.0383 - code_naming_output_loss: 0.0387 - code_logic_output_loss: 0.1207 - code_io_output_loss: 0.0755 - code_data_output_loss: 0.0966 - code_doc_output_loss: 0.0749 - code_api_output_loss: 0.0736 - compatibility_output_loss: 0.0658 - rule_def_output_loss: 0.0681 - config_commit_patch_review_output_loss: 0.0521 - config_building_installing_output_loss: 0.0591 - code_design_output_accuracy: 0.9620 - code_style_output_accuracy: 0.9936 - code_naming_output_accuracy: 0.9892 - code_logic_output_accuracy: 0.9596 - code_io_output_accuracy: 0.9768 - code_data_output_accuracy: 0.9712 - code_doc_output_accuracy: 0.9780 - code_api_output_accuracy: 0.9808 - compatibility_output_accuracy: 0.9788 - rule_def_output_accuracy: 0.9824 - config_commit_patch_review_output_accuracy: 0.9852 - config_building_installing_output_accuracy: 0.9780\n",
      "Epoch 10/15\n",
      "105/105 [==============================] - 101s 963ms/step - loss: 0.7005 - code_design_output_loss: 0.0800 - code_style_output_loss: 0.0331 - code_naming_output_loss: 0.0334 - code_logic_output_loss: 0.0876 - code_io_output_loss: 0.0660 - code_data_output_loss: 0.0794 - code_doc_output_loss: 0.0601 - code_api_output_loss: 0.0607 - compatibility_output_loss: 0.0525 - rule_def_output_loss: 0.0597 - config_commit_patch_review_output_loss: 0.0404 - config_building_installing_output_loss: 0.0476 - code_design_output_accuracy: 0.9776 - code_style_output_accuracy: 0.9932 - code_naming_output_accuracy: 0.9916 - code_logic_output_accuracy: 0.9728 - code_io_output_accuracy: 0.9780 - code_data_output_accuracy: 0.9760 - code_doc_output_accuracy: 0.9828 - code_api_output_accuracy: 0.9860 - compatibility_output_accuracy: 0.9840 - rule_def_output_accuracy: 0.9836 - config_commit_patch_review_output_accuracy: 0.9900 - config_building_installing_output_accuracy: 0.9860\n",
      "Epoch 11/15\n",
      "105/105 [==============================] - 101s 962ms/step - loss: 0.5525 - code_design_output_loss: 0.0576 - code_style_output_loss: 0.0274 - code_naming_output_loss: 0.0268 - code_logic_output_loss: 0.0803 - code_io_output_loss: 0.0517 - code_data_output_loss: 0.0603 - code_doc_output_loss: 0.0456 - code_api_output_loss: 0.0454 - compatibility_output_loss: 0.0396 - rule_def_output_loss: 0.0475 - config_commit_patch_review_output_loss: 0.0337 - config_building_installing_output_loss: 0.0367 - code_design_output_accuracy: 0.9844 - code_style_output_accuracy: 0.9956 - code_naming_output_accuracy: 0.9960 - code_logic_output_accuracy: 0.9780 - code_io_output_accuracy: 0.9812 - code_data_output_accuracy: 0.9848 - code_doc_output_accuracy: 0.9868 - code_api_output_accuracy: 0.9904 - compatibility_output_accuracy: 0.9888 - rule_def_output_accuracy: 0.9880 - config_commit_patch_review_output_accuracy: 0.9920 - config_building_installing_output_accuracy: 0.9904\n",
      "Epoch 12/15\n",
      "105/105 [==============================] - 101s 962ms/step - loss: 0.4636 - code_design_output_loss: 0.0499 - code_style_output_loss: 0.0246 - code_naming_output_loss: 0.0260 - code_logic_output_loss: 0.0651 - code_io_output_loss: 0.0420 - code_data_output_loss: 0.0527 - code_doc_output_loss: 0.0372 - code_api_output_loss: 0.0368 - compatibility_output_loss: 0.0347 - rule_def_output_loss: 0.0404 - config_commit_patch_review_output_loss: 0.0258 - config_building_installing_output_loss: 0.0286 - code_design_output_accuracy: 0.9864 - code_style_output_accuracy: 0.9972 - code_naming_output_accuracy: 0.9940 - code_logic_output_accuracy: 0.9832 - code_io_output_accuracy: 0.9852 - code_data_output_accuracy: 0.9876 - code_doc_output_accuracy: 0.9892 - code_api_output_accuracy: 0.9916 - compatibility_output_accuracy: 0.9900 - rule_def_output_accuracy: 0.9888 - config_commit_patch_review_output_accuracy: 0.9948 - config_building_installing_output_accuracy: 0.9924\n",
      "Epoch 13/15\n",
      "105/105 [==============================] - 101s 962ms/step - loss: 0.3813 - code_design_output_loss: 0.0309 - code_style_output_loss: 0.0234 - code_naming_output_loss: 0.0225 - code_logic_output_loss: 0.0563 - code_io_output_loss: 0.0295 - code_data_output_loss: 0.0431 - code_doc_output_loss: 0.0281 - code_api_output_loss: 0.0369 - compatibility_output_loss: 0.0291 - rule_def_output_loss: 0.0314 - config_commit_patch_review_output_loss: 0.0230 - config_building_installing_output_loss: 0.0269 - code_design_output_accuracy: 0.9940 - code_style_output_accuracy: 0.9952 - code_naming_output_accuracy: 0.9944 - code_logic_output_accuracy: 0.9860 - code_io_output_accuracy: 0.9920 - code_data_output_accuracy: 0.9908 - code_doc_output_accuracy: 0.9932 - code_api_output_accuracy: 0.9904 - compatibility_output_accuracy: 0.9928 - rule_def_output_accuracy: 0.9928 - config_commit_patch_review_output_accuracy: 0.9952 - config_building_installing_output_accuracy: 0.9928\n",
      "Epoch 14/15\n",
      "105/105 [==============================] - 101s 965ms/step - loss: 0.3115 - code_design_output_loss: 0.0225 - code_style_output_loss: 0.0227 - code_naming_output_loss: 0.0142 - code_logic_output_loss: 0.0534 - code_io_output_loss: 0.0262 - code_data_output_loss: 0.0369 - code_doc_output_loss: 0.0212 - code_api_output_loss: 0.0306 - compatibility_output_loss: 0.0206 - rule_def_output_loss: 0.0275 - config_commit_patch_review_output_loss: 0.0164 - config_building_installing_output_loss: 0.0193 - code_design_output_accuracy: 0.9968 - code_style_output_accuracy: 0.9948 - code_naming_output_accuracy: 0.9988 - code_logic_output_accuracy: 0.9840 - code_io_output_accuracy: 0.9952 - code_data_output_accuracy: 0.9916 - code_doc_output_accuracy: 0.9960 - code_api_output_accuracy: 0.9936 - compatibility_output_accuracy: 0.9956 - rule_def_output_accuracy: 0.9948 - config_commit_patch_review_output_accuracy: 0.9980 - config_building_installing_output_accuracy: 0.9972\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 101s 963ms/step - loss: 0.2355 - code_design_output_loss: 0.0182 - code_style_output_loss: 0.0154 - code_naming_output_loss: 0.0133 - code_logic_output_loss: 0.0332 - code_io_output_loss: 0.0192 - code_data_output_loss: 0.0311 - code_doc_output_loss: 0.0182 - code_api_output_loss: 0.0206 - compatibility_output_loss: 0.0160 - rule_def_output_loss: 0.0212 - config_commit_patch_review_output_loss: 0.0135 - config_building_installing_output_loss: 0.0155 - code_design_output_accuracy: 0.9976 - code_style_output_accuracy: 0.9976 - code_naming_output_accuracy: 0.9984 - code_logic_output_accuracy: 0.9952 - code_io_output_accuracy: 0.9956 - code_data_output_accuracy: 0.9940 - code_doc_output_accuracy: 0.9976 - code_api_output_accuracy: 0.9976 - compatibility_output_accuracy: 0.9972 - rule_def_output_accuracy: 0.9960 - config_commit_patch_review_output_accuracy: 0.9992 - config_building_installing_output_accuracy: 0.9980\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_seed)\n",
    "set_random_seed(random_seed)\n",
    "\n",
    "batch_size = 24\n",
    "epochs = 15\n",
    "lr=2e-5\n",
    "layers_num=12\n",
    "\n",
    "model = get_model(seq_len, subject_columns, layers_num, config_path, checkpoint_path, lr)\n",
    "\n",
    "history = model.fit(\n",
    "                x_train,\n",
    "                y_all_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                verbose=1,\n",
    "                shuffle=True,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T08:37:05.828699Z",
     "start_time": "2021-06-29T08:37:00.664836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001D0C70BD2F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001D0C70BD2F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting...\")\n",
    "y_pred_subject = model.predict(x_test) \n",
    "\n",
    "y_pred_subject = np.array(y_pred_subject).reshape(len(y_pred_subject),len(y_pred_subject[0])).transpose()\n",
    "subject_all_preds = []\n",
    "for preds in y_pred_subject:\n",
    "    subject_all_preds.append([1 if x > 0.5 else 0 for x in preds]) \n",
    "subject_preds_df = pd.DataFrame(subject_all_preds, columns=subject_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T09:35:27.575042Z",
     "start_time": "2021-06-29T09:35:25.553176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject code_design AUC = 0.49\n",
      "Subject code_design Accuracy = 0.96\n",
      "Subject code_design Precision (macro) = 0.49\n",
      "Subject code_design Recall (macro) = 0.49\n",
      "Subject code_design F1-score (macro) = 0.49\n",
      "Subject code_design Precision (micro) = 0.96\n",
      "Subject code_design Recall (micro) = 0.96\n",
      "Subject code_design F1-score (micro) = 0.96\n",
      "Subject code_design Precision (binary) = 0.0\n",
      "Subject code_design Recall (binary) = 0.0\n",
      "Subject code_design F1-score (binary) = 0.0\n",
      "Subject code_design MCC = -0.021\n",
      "Subject code_style AUC = 0.9\n",
      "Subject code_style Accuracy = 0.95\n",
      "Subject code_style Precision (macro) = 0.9\n",
      "Subject code_style Recall (macro) = 0.9\n",
      "Subject code_style F1-score (macro) = 0.9\n",
      "Subject code_style Precision (micro) = 0.95\n",
      "Subject code_style Recall (micro) = 0.95\n",
      "Subject code_style F1-score (micro) = 0.95\n",
      "Subject code_style Precision (binary) = 0.82\n",
      "Subject code_style Recall (binary) = 0.82\n",
      "Subject code_style F1-score (binary) = 0.82\n",
      "Subject code_style MCC = 0.79\n",
      "Subject code_naming AUC = 0.8\n",
      "Subject code_naming Accuracy = 0.99\n",
      "Subject code_naming Precision (macro) = 0.99\n",
      "Subject code_naming Recall (macro) = 0.8\n",
      "Subject code_naming F1-score (macro) = 0.87\n",
      "Subject code_naming Precision (micro) = 0.99\n",
      "Subject code_naming Recall (micro) = 0.99\n",
      "Subject code_naming F1-score (micro) = 0.99\n",
      "Subject code_naming Precision (binary) = 1.0\n",
      "Subject code_naming Recall (binary) = 0.6\n",
      "Subject code_naming F1-score (binary) = 0.75\n",
      "Subject code_naming MCC = 0.77\n",
      "Subject code_logic AUC = 0.87\n",
      "Subject code_logic Accuracy = 0.86\n",
      "Subject code_logic Precision (macro) = 0.86\n",
      "Subject code_logic Recall (macro) = 0.87\n",
      "Subject code_logic F1-score (macro) = 0.86\n",
      "Subject code_logic Precision (micro) = 0.86\n",
      "Subject code_logic Recall (micro) = 0.86\n",
      "Subject code_logic F1-score (micro) = 0.86\n",
      "Subject code_logic Precision (binary) = 0.92\n",
      "Subject code_logic Recall (binary) = 0.83\n",
      "Subject code_logic F1-score (binary) = 0.87\n",
      "Subject code_logic MCC = 0.72\n",
      "Subject code_io AUC = 0.5\n",
      "Subject code_io Accuracy = 0.99\n",
      "Subject code_io Precision (macro) = 0.5\n",
      "Subject code_io Recall (macro) = 0.5\n",
      "Subject code_io F1-score (macro) = 0.5\n",
      "Subject code_io Precision (micro) = 0.99\n",
      "Subject code_io Recall (micro) = 0.99\n",
      "Subject code_io F1-score (micro) = 0.99\n",
      "Subject code_io Precision (binary) = 0.0\n",
      "Subject code_io Recall (binary) = 0.0\n",
      "Subject code_io F1-score (binary) = 0.0\n",
      "Subject code_io MCC = 0.0\n",
      "Subject code_data AUC = 0.77\n",
      "Subject code_data Accuracy = 0.81\n",
      "Subject code_data Precision (macro) = 0.82\n",
      "Subject code_data Recall (macro) = 0.77\n",
      "Subject code_data F1-score (macro) = 0.78\n",
      "Subject code_data Precision (micro) = 0.81\n",
      "Subject code_data Recall (micro) = 0.81\n",
      "Subject code_data F1-score (micro) = 0.81\n",
      "Subject code_data Precision (binary) = 0.85\n",
      "Subject code_data Recall (binary) = 0.61\n",
      "Subject code_data F1-score (binary) = 0.71\n",
      "Subject code_data MCC = 0.59\n",
      "Subject code_doc Accuracy = 1.00\n",
      "Subject code_doc Precision (macro) = 1.0\n",
      "Subject code_doc Recall (macro) = 1.0\n",
      "Subject code_doc F1-score (macro) = 1.0\n",
      "Subject code_doc Precision (micro) = 1.0\n",
      "Subject code_doc Recall (micro) = 1.0\n",
      "Subject code_doc F1-score (micro) = 1.0\n",
      "Subject code_doc Precision (binary) = 0.0\n",
      "Subject code_doc Recall (binary) = 0.0\n",
      "Subject code_doc F1-score (binary) = 0.0\n",
      "Subject code_doc MCC = 0.0\n",
      "Subject code_api AUC = 0.77\n",
      "Subject code_api Accuracy = 0.88\n",
      "Subject code_api Precision (macro) = 0.69\n",
      "Subject code_api Recall (macro) = 0.77\n",
      "Subject code_api F1-score (macro) = 0.72\n",
      "Subject code_api Precision (micro) = 0.88\n",
      "Subject code_api Recall (micro) = 0.88\n",
      "Subject code_api F1-score (micro) = 0.88\n",
      "Subject code_api Precision (binary) = 0.42\n",
      "Subject code_api Recall (binary) = 0.62\n",
      "Subject code_api F1-score (binary) = 0.5\n",
      "Subject code_api MCC = 0.45\n",
      "Subject compatibility AUC = 0.59\n",
      "Subject compatibility Accuracy = 0.97\n",
      "Subject compatibility Precision (macro) = 0.65\n",
      "Subject compatibility Recall (macro) = 0.59\n",
      "Subject compatibility F1-score (macro) = 0.62\n",
      "Subject compatibility Precision (micro) = 0.97\n",
      "Subject compatibility Recall (micro) = 0.97\n",
      "Subject compatibility F1-score (micro) = 0.97\n",
      "Subject compatibility Precision (binary) = 0.33\n",
      "Subject compatibility Recall (binary) = 0.2\n",
      "Subject compatibility F1-score (binary) = 0.25\n",
      "Subject compatibility MCC = 0.24\n",
      "Subject rule_def AUC = 1.0\n",
      "Subject rule_def Accuracy = 1.00\n",
      "Subject rule_def Precision (macro) = 1.0\n",
      "Subject rule_def Recall (macro) = 1.0\n",
      "Subject rule_def F1-score (macro) = 1.0\n",
      "Subject rule_def Precision (micro) = 1.0\n",
      "Subject rule_def Recall (micro) = 1.0\n",
      "Subject rule_def F1-score (micro) = 1.0\n",
      "Subject rule_def Precision (binary) = 1.0\n",
      "Subject rule_def Recall (binary) = 1.0\n",
      "Subject rule_def F1-score (binary) = 1.0\n",
      "Subject rule_def MCC = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject config_commit_patch_review Accuracy = 0.99\n",
      "Subject config_commit_patch_review Precision (macro) = 0.5\n",
      "Subject config_commit_patch_review Recall (macro) = 0.49\n",
      "Subject config_commit_patch_review F1-score (macro) = 0.5\n",
      "Subject config_commit_patch_review Precision (micro) = 0.99\n",
      "Subject config_commit_patch_review Recall (micro) = 0.99\n",
      "Subject config_commit_patch_review F1-score (micro) = 0.99\n",
      "Subject config_commit_patch_review Precision (binary) = 0.0\n",
      "Subject config_commit_patch_review Recall (binary) = 0.0\n",
      "Subject config_commit_patch_review F1-score (binary) = 0.0\n",
      "Subject config_commit_patch_review MCC = 0.0\n",
      "Subject config_building_installing AUC = 0.5\n",
      "Subject config_building_installing Accuracy = 0.99\n",
      "Subject config_building_installing Precision (macro) = 0.49\n",
      "Subject config_building_installing Recall (macro) = 0.5\n",
      "Subject config_building_installing F1-score (macro) = 0.5\n",
      "Subject config_building_installing Precision (micro) = 0.99\n",
      "Subject config_building_installing Recall (micro) = 0.99\n",
      "Subject config_building_installing F1-score (micro) = 0.99\n",
      "Subject config_building_installing Precision (binary) = 0.0\n",
      "Subject config_building_installing Recall (binary) = 0.0\n",
      "Subject config_building_installing F1-score (binary) = 0.0\n",
      "Subject config_building_installing MCC = 0.0\n",
      "Preparing confusion matrix for the comment subjects.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\ipykernel_launcher.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\user\\Anaconda3\\envs\\ml2\\lib\\site-packages\\matplotlib\\figure.py:2299: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not compatible \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for the comment subject saved to ./output/cross-mono-subject_cm.pdf.\n"
     ]
    }
   ],
   "source": [
    "y_true_df = pd.DataFrame(y_all_test)\n",
    "y_true_df.columns = [str(col).replace(\"_output\", \"\") for col in y_true_df.columns]\n",
    "\n",
    "results = dict()\n",
    "\n",
    "for subject in subject_columns:\n",
    "    subject_acc = accuracy_score(y_true_df[subject], subject_preds_df[subject])\n",
    "    subject_f1 = f1_score(y_true_df[subject], subject_preds_df[subject], average=\"macro\")\n",
    "    subject_precision = precision_score(y_true_df[subject], subject_preds_df[subject], average=\"macro\")\n",
    "    subject_recall = recall_score(y_true_df[subject], subject_preds_df[subject], average=\"macro\")\n",
    "    subject_f1_micro = f1_score(y_true_df[subject], subject_preds_df[subject], average=\"micro\")\n",
    "    subject_precision_micro = precision_score(y_true_df[subject], subject_preds_df[subject], average=\"micro\")\n",
    "    subject_recall_micro = recall_score(y_true_df[subject], subject_preds_df[subject], average=\"micro\")\n",
    "    subject_f1_binary = f1_score(y_true_df[subject], subject_preds_df[subject], average=\"binary\")\n",
    "    subject_precision_binary = precision_score(y_true_df[subject], subject_preds_df[subject], average=\"binary\")\n",
    "    subject_recall_binary = recall_score(y_true_df[subject], subject_preds_df[subject], average=\"binary\")\n",
    "    subject_mcc = mcc_score(y_true_df[subject], subject_preds_df[subject])    \n",
    "    try:\n",
    "        subject_roc_auc_score = roc_auc_score(y_true_df[subject], subject_preds_df[subject])\n",
    "        print(f\"Subject {subject} AUC = {subject_roc_auc_score:.2}\")\n",
    "    except:\n",
    "        subject_roc_auc_score = None\n",
    "    \n",
    "    print(f\"Subject {subject} Accuracy = {subject_acc:.2f}\")\n",
    "    print(f\"Subject {subject} Precision (macro) = {subject_precision:.2}\")\n",
    "    print(f\"Subject {subject} Recall (macro) = {subject_recall:.2}\")\n",
    "    print(f\"Subject {subject} F1-score (macro) = {subject_f1:.2}\")\n",
    "    print(f\"Subject {subject} Precision (micro) = {subject_precision_micro:.2}\")\n",
    "    print(f\"Subject {subject} Recall (micro) = {subject_recall_micro:.2}\")\n",
    "    print(f\"Subject {subject} F1-score (micro) = {subject_f1_micro:.2}\")\n",
    "    print(f\"Subject {subject} Precision (binary) = {subject_precision_binary:.2}\")\n",
    "    print(f\"Subject {subject} Recall (binary) = {subject_recall_binary:.2}\")\n",
    "    print(f\"Subject {subject} F1-score (binary) = {subject_f1_binary:.2}\")\n",
    "    print(f\"Subject {subject} MCC = {subject_mcc:.2}\")\n",
    "\n",
    "\n",
    "    results[subject] = dict()\n",
    "    results[subject]['acc'] = subject_acc\n",
    "    results[subject]['rec_macro']= subject_recall\n",
    "    results[subject]['prec_macro'] = subject_precision\n",
    "    results[subject]['fscore_macro'] = subject_f1\n",
    "    results[subject]['rec_micro']= subject_recall_micro\n",
    "    results[subject]['prec_micro'] = subject_precision_micro\n",
    "    results[subject]['fscore_micro'] = subject_f1_micro\n",
    "    results[subject]['rec_binary']= subject_recall_binary\n",
    "    results[subject]['prec_binary'] = subject_precision_binary\n",
    "    results[subject]['fscore_binary'] = subject_f1_binary\n",
    "    results[subject]['mcc'] = subject_mcc\n",
    "    results[subject]['auc'] = subject_roc_auc_score\n",
    "    \n",
    "subject_cm_path=f\"./output/cross-mono-subject_cm.pdf\"\n",
    "print(\"Preparing confusion matrix for the comment subjects.\")\n",
    "\n",
    "figsize=(10,20)\n",
    "cmap='Greens'\n",
    "\n",
    "cf_matrix_all_subject = multilabel_confusion_matrix(y_true_df[subject_columns].values,\n",
    "                                                    subject_preds_df[subject_columns].values, samplewise=False)\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "cols = math.ceil(float(len(subject_columns)) / 2.0)\n",
    "#print(cols)\n",
    "gs = gridspec.GridSpec(cols, 2, height_ratios=[1]*cols)\n",
    "gs.update(hspace=0.4, wspace=0.5)\n",
    "\n",
    "for i, cf in enumerate(cf_matrix_all_subject):\n",
    "\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    #print(row, col)\n",
    "    ax = plt.subplot(gs[row, col])\n",
    "\n",
    "    cmn = cf.astype('float') / cf.sum(axis=1)[:, np.newaxis]\n",
    "    perc_labs = [\"{0:.1%}\".format(value) for value in cmn.flatten()]\n",
    "\n",
    "    group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}\".strip() for v1, v2 in zip(group_counts,perc_labs)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "    sns.heatmap(cmn, \n",
    "                annot=box_labels, \n",
    "                fmt='', \n",
    "                annot_kws={\"fontsize\":12},\n",
    "                xticklabels=(\"False\", \"True\"), \n",
    "                yticklabels=(\"False\", \"True\"),\n",
    "            cmap=cmap,\n",
    "            linecolor='lightgray', linewidths=0.5,\n",
    "            square=True,\n",
    "            cbar=False,\n",
    "            vmin=0, vmax=1)\n",
    "    ax.set_title(subject_columns[i])\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(subject_cm_path)\n",
    "print(f\"Confusion matrix for the comment subject saved to {subject_cm_path}.\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T09:36:50.608098Z",
     "start_time": "2021-06-29T09:36:50.588105Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./output/res-cross-mono.json', 'w') as fp:\n",
    "    json.dump(results, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T09:39:13.300392Z",
     "start_time": "2021-06-29T09:39:13.275399Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_excel('./output/res-cross-mono.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T09:43:52.087782Z",
     "start_time": "2021-06-29T09:43:52.021782Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df = results_df\n",
    "reviews_df = reviews_test_df\n",
    "\n",
    "counts_df = reviews_df[subject_columns].sum()\n",
    "counts_df.name = \"n\"\n",
    "\n",
    "perc_counts_df = reviews_df[subject_columns].sum() / reviews_df.shape[0]\n",
    "perc_counts_df.name = \"perc_count\"\n",
    "\n",
    "summary_dfs = [counts_df, perc_counts_df]\n",
    "for metric in results_df.index.unique().tolist():\n",
    "    metric_df = results_df[results_df.index == metric].mean()\n",
    "    metric_df.name = metric\n",
    "    summary_dfs.append(metric_df)\n",
    "    \n",
    "summary_df = pd.concat(summary_dfs, axis=1)\n",
    "summary_df.to_excel('./output/summary-cross-mono.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-ml2",
   "language": "python",
   "name": "python-ml2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
